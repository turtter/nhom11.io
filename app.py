import streamlit as st
from PIL import Image, ImageDraw
import torch
import torchvision
import torchvision.transforms as T
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
<<<<<<< HEAD


# ================================
# 1Ô∏è‚É£ H√†m load model (s·ª≠a num_classes = 4)
# ================================
def load_model(weight_path):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1
    )

    # 3 l·ªõp (non_defective_phone, defective, non-phone) + 1 background
    num_classes = 4

    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # Load tr·ªçng s·ªë hu·∫•n luy·ªán
    state_dict = torch.load(weight_path, map_location="cpu")
    model.load_state_dict(state_dict)

=======
import os
import pickle
import numpy as np

# --- Import c√°c th∆∞ vi·ªán HOG ---
from skimage.transform import resize
from skimage.color import rgb2gray
from skimage.feature import hog

# ======================================================================
# MODEL 1: FASTER R-CNN (Ph√°t hi·ªán L·ªói)
# ======================================================================

# 1.1Ô∏è‚É£ H√†m load model (s·ª≠a num_classes = 4)
def load_model_fasterrcnn(weight_path):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1
    )
    num_classes = 4  # 3 l·ªõp + 1 background
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    state_dict = torch.load(weight_path, map_location="cpu")
    model.load_state_dict(state_dict)
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
    model.eval()
    return model


<<<<<<< HEAD
# ================================
# 2Ô∏è‚É£ T·∫£i m√¥ h√¨nh ch·ªâ 1 l·∫ßn
# ================================
@st.cache_resource
def get_model():
    model_path = "fasterrcnn_phone_defect1910.pth"  # ƒë∆∞·ªùng d·∫´n file .pth c·ªßa b·∫°n
    model = load_model(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("‚úÖ Model loaded and cached.")
    return model, device


# ================================
# 3Ô∏è‚É£ H√†m d·ª± ƒëo√°n cho Web App
# ================================
=======
# 1.2Ô∏è‚É£ T·∫£i m√¥ h√¨nh ch·ªâ 1 l·∫ßn
@st.cache_resource
def get_model_fasterrcnn():
    model_path = "fasterrcnn_phone_defect1910.pth"  # ƒë∆∞·ªùng d·∫´n file .pth c·ªßa b·∫°n
    model = load_model_fasterrcnn(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("‚úÖ Model 1 (Faster R-CNN) loaded and cached.")
    return model, device


# 1.3Ô∏è‚É£ H√†m d·ª± ƒëo√°n cho Web App (Ch·ªâ tr·∫£ v·ªÅ STATUS)
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
def predict_for_webapp(model, device, image_pil, score_thresh=0.6):
    transform = T.ToTensor()
    img_tensor = transform(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)[0]
<<<<<<< HEAD

    image_with_boxes = image_pil.copy()
    draw = ImageDraw.Draw(image_with_boxes)

    # Map ID -> Nh√£n
    label_map = {
        1: "KH√îNG L·ªñI",
        2: "B·ªä L·ªñI",
        3: "KH√îNG PH·∫¢I ƒêI·ªÜN THO·∫†I"
    }

=======
        
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
    has_detection = False
    found_defect = False
    found_nonphone = False

<<<<<<< HEAD
    for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            has_detection = True
            box = box.cpu().numpy()
            label_id = int(label.cpu().numpy())

            # M√†u khung
            if label_id == 1:
                color = "lime"
            elif label_id == 2:
                color = "red"
                found_defect = True
            elif label_id == 3:
                color = "blue"
                found_nonphone = True
            else:
                color = "white"

            # V·∫Ω khung v√† nh√£n
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)
            text = f"{label_map.get(label_id, 'N/A')}: {score:.2f}"
            text_x, text_y = box[0], max(0, box[1] - 20)
            bbox = draw.textbbox((text_x, text_y), text)
            draw.rectangle(bbox, fill="black")
            draw.text((text_x, text_y), text, fill="yellow")

    # ================================
    # 4Ô∏è‚É£ Logic k·∫øt lu·∫≠n
    # ================================
    if not has_detection or found_nonphone:
        return "NO_PHONE", image_with_boxes
    elif found_defect:
        return "DEFECTIVE", image_with_boxes
    else:
        return "NON_DEFECTIVE", image_with_boxes


# ================================
# 5Ô∏è‚É£ Giao di·ªán Streamlit
# ================================
st.set_page_config(layout="wide", page_title="Phone Defect Detection")

st.title("üì± ·ª®ng d·ª•ng Ph√°t hi·ªán L·ªói ƒêi·ªán tho·∫°i (3 l·ªõp)")
st.write("T·∫£i l√™n ·∫£nh ƒëi·ªán tho·∫°i ƒë·ªÉ m√¥ h√¨nh ph√¢n lo·∫°i: **KH√îNG L·ªñI**, **B·ªä L·ªñI**, ho·∫∑c **KH√îNG PH√ÅT HI·ªÜN RA ƒêI·ªÜN THO·∫†I**.")

model, device = get_model()

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader("üì§ Ch·ªçn m·ªôt ·∫£nh", type=["jpg", "jpeg", "png"])

with col2:
    st.write("### üîç K·∫øt qu·∫£ d·ª± ƒëo√°n")

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            detection_status, result_image = predict_for_webapp(model, device, image, score_thresh=0.6)

            if detection_status == "DEFECTIVE":
                st.error("‚ùå **K·∫æT QU·∫¢: PH√ÅT HI·ªÜN ƒêI·ªÜN THO·∫†I B·ªä L·ªñI (V·ª† ho·∫∑c B·∫®N )**")
            elif detection_status == "NON_DEFECTIVE":
                st.success("‚úÖ **K·∫æT QU·∫¢: ƒêI·ªÜN THO·∫†I KH√îNG L·ªñI**")
            elif detection_status == "NO_PHONE":
                st.warning("‚ö†Ô∏è **K·∫æT QU·∫¢: KH√îNG PH√ÅT HI·ªÜN RA ƒêI·ªÜN THO·∫†I**")

            st.image(result_image, caption="·∫¢nh K·∫øt Qu·∫£", use_container_width=True)
    else:
        st.info("‚¨ÜÔ∏è H√£y t·∫£i m·ªôt ·∫£nh l√™n ƒë·ªÉ xem k·∫øt qu·∫£.")
=======
    for score, label in zip(outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            has_detection = True
            label_id = int(label.cpu().numpy())
            if label_id == 2:
                found_defect = True
            elif label_id == 3:
                found_nonphone = True

    # 1.4Ô∏è‚É£ Logic k·∫øt lu·∫≠n (Kh√¥ng tr·∫£ v·ªÅ ·∫£nh)
    if not has_detection or found_nonphone:
        return "NO_PHONE"
    elif found_defect:
        return "DEFECTIVE"
    else:
        return "NON_DEFECTIVE"


# ======================================================================
# MODEL 2: HOG + SOFTMAX (Ph√¢n lo·∫°i)
# ======================================================================

# 2.1Ô∏è‚É£ --- CONFIG HOG (Ph·∫£i gi·ªëng h·ªát file train) ---
HOG_IMG_SIZE = (128, 64)
PIXELS_PER_CELL = (16, 16)
CELLS_PER_BLOCK = (2, 2)
ORIENTATIONS = 9
COLOR_BINS = 32
MODEL_PATH = os.path.join("outputs", "softmax_model_hog_hist.pkl")

# 2.2Ô∏è‚É£ --- T·∫£i Model ƒë√£ hu·∫•n luy·ªán ---
@st.cache_resource
def load_model_hog():
    if not os.path.exists(MODEL_PATH):
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file model HOG t·∫°i '{MODEL_PATH}'")
        return None  # Tr·∫£ v·ªÅ None n·∫øu l·ªói
    print(f"ƒêang t·∫£i model HOG t·ª´ {MODEL_PATH}...")
    try:
        with open(MODEL_PATH, "rb") as f:
            model_data = pickle.load(f)
        print("T·∫£i model HOG th√†nh c√¥ng.")
        return model_data
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i model HOG: {e}")
        return None # Tr·∫£ v·ªÅ None n·∫øu l·ªói


# 2.3Ô∏è‚É£ --- H√†m t√≠nh Softmax (L·∫•y t·ª´ file train) ---
def softmax_np(z):
    z = z - np.max(z, axis=1, keepdims=True)
    e = np.exp(z)
    return e / np.sum(e, axis=1, keepdims=True)


# 2.4Ô∏è‚É£ --- H√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG (ƒê√É C·∫¨P NH·∫¨T) ---
def extract_hog_features(img_pil):
    try:
        img = np.array(img_pil)
        if img.ndim == 3 and img.shape[2] == 4:
            img = img[:, :, :3]  # Lo·∫°i b·ªè k√™nh Alpha
        resized_img = resize(img, HOG_IMG_SIZE, anti_aliasing=True)
        gray_img = rgb2gray(resized_img) if resized_img.ndim == 3 else resized_img
        features_hog = hog(gray_img, orientations=ORIENTATIONS,
                           pixels_per_cell=PIXELS_PER_CELL,
                           cells_per_block=CELLS_PER_BLOCK,
                           block_norm='L2-Hys',
                           visualize=False,
                           transform_sqrt=True)
        if resized_img.ndim == 3 and resized_img.shape[2] == 3:
            img_uint8 = (resized_img * 255).astype(np.uint8)
            hist_r = np.histogram(img_uint8[:, :, 0], bins=COLOR_BINS, range=(0, 256))[0]
            hist_g = np.histogram(img_uint8[:, :, 1], bins=COLOR_BINS, range=(0, 256))[0]
            hist_b = np.histogram(img_uint8[:, :, 2], bins=COLOR_BINS, range=(0, 256))[0]
            features_color_raw = np.concatenate((hist_r, hist_g, hist_b))
            features_color = features_color_raw / (features_color_raw.sum() + 1e-6)
        else:
            features_color = np.zeros(COLOR_BINS * 3)
        features = np.concatenate((features_hog, features_color))
        return features
    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t HOG: {e}")
        return None


# ======================================================================
# 5Ô∏è‚É£ Giao di·ªán Streamlit Ch√≠nh (K·∫øt qu·∫£ l√™n ƒë·∫ßu)
# ======================================================================
st.set_page_config(layout="wide", page_title="Phone Analysis App")

st.title("üì± ·ª®ng d·ª•ng Ph√¢n t√≠ch ƒêi·ªán tho·∫°i")
st.write("T·∫£i l√™n m·ªôt ·∫£nh, c·∫£ hai m√¥ h√¨nh s·∫Ω c√πng ph√¢n t√≠ch v√† hi·ªÉn th·ªã k·∫øt qu·∫£ ngay b√™n d∆∞·ªõi.")

# --- T·∫£i c·∫£ hai model l√™n tr∆∞·ªõc ---
model_rcnn, device_rcnn = get_model_fasterrcnn()
model_data_hog = load_model_hog()

# --- T·∫°o 1 file uploader duy nh·∫•t ---
uploaded_file = st.file_uploader("üì§ Ch·ªçn m·ªôt ·∫£nh duy nh·∫•t", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # M·ªü ·∫£nh M·ªòT L·∫¶N
    image_pil = Image.open(uploaded_file).convert("RGB")

    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ (Theo y√™u c·∫ßu) ---
    st.header("üîç K·∫øt Qu·∫£ Ph√¢n T√≠ch")
    
    # T·∫°o 2 d√≤ng tr·ªëng ƒë·ªÉ ch·ª©a k·∫øt qu·∫£
    # Ch√∫ng s·∫Ω ƒë∆∞·ª£c l·∫•p ƒë·∫ßy sau khi model ch·∫°y xong
    result_placeholder_1 = st.empty()
    result_placeholder_2 = st.empty()

    # Th√™m m·ªôt ƒë∆∞·ªùng k·∫ª
    st.divider() 

    # --- HI·ªÇN TH·ªä ·∫¢NH G·ªêC (B√™n d∆∞·ªõi k·∫øt qu·∫£) ---
    st.header("üñºÔ∏è ·∫¢nh G·ªëc ƒê√£ T·∫£i L√™n")
    st.image(image_pil, caption="·∫¢nh g·ªëc", use_container_width=True)
    
    # --- X·ª≠ l√Ω Model 1 (Faster R-CNN) ---
    with st.spinner("Model 1 (Faster R-CNN) ƒëang x·ª≠ l√Ω..."):
        detection_status = predict_for_webapp(model_rcnn, device_rcnn, image_pil.copy(), score_thresh=0.6)
        
        # Format k·∫øt qu·∫£ Model 1 (ƒê√É S·ª¨A T√äN)
        result_text_1 = "### 1. Model Faster R-CNN: "
        if detection_status == "DEFECTIVE":
            result_text_1 += "‚ùå **PH√ÅT HI·ªÜN L·ªñI (V·ª†/B·∫®N)**"
        elif detection_status == "NON_DEFECTIVE":
            result_text_1 += "‚úÖ **KH√îNG L·ªñI**"
        elif detection_status == "NO_PHONE":
            result_text_1 += "‚ö†Ô∏è **KH√îNG PH√ÅT HI·ªÜN ƒêT**"
        
        # ƒê·∫©y k·∫øt qu·∫£ v√†o placeholder 1
        result_placeholder_1.markdown(result_text_1)

    # --- X·ª≠ l√Ω Model 2 (HOG + Softmax) ---
    with st.spinner("Model 2 (Softmax regression) ƒëang x·ª≠ l√Ω..."):
        if model_data_hog is not None:
            # Gi·∫£i n√©n c√°c th√†nh ph·∫ßn model HOG
            W = model_data_hog["W"]
            b = model_data_hog["b"]
            mean = model_data_hog["mean"]
            std = model_data_hog["std"]
            label_map = model_data_hog["label_map"]
            inv_label_map = {v: k for k, v in label_map.items()}

            features = extract_hog_features(image_pil.copy())
            
            # Format k·∫øt qu·∫£ Model 2 (ƒê√É S·ª¨A T√äN)
            result_text_2 = "### 2. Model Softmax regression: "
            if features is None:
                result_text_2 += "üö´ *Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh n√†y.*"
            else:
                features_2d = features.reshape(1, -1)
                if features_2d.shape[1] != mean.shape[1]:
                    result_text_2 += f"üö´ *L·ªói k√≠ch th∆∞·ªõc! (C·∫ßn {mean.shape[1]}, nh·∫≠n ƒë∆∞·ª£c {features_2d.shape[1]})*"
                else:
                    # Chu·∫©n h√≥a v√† d·ª± ƒëo√°n
                    features_std = (features_2d - mean) / (std + 1e-12)
                    scores = features_std @ W + b
                    probs = softmax_np(scores)
                    pred_index = np.argmax(probs, axis=1)[0]
                    prediction_label = inv_label_map[pred_index]
                    probability = np.max(probs) * 100
                    
                    # Format k·∫øt qu·∫£ Model 2
                    result_text_2 += f"**'{prediction_label}'** (ƒê·ªô tin c·∫≠y: {probability:.2f}%)"
            
            # ƒê·∫©y k·∫øt qu·∫£ v√†o placeholder 2
            result_placeholder_2.markdown(result_text_2)
        else:
            result_placeholder_2.error("### 2. Model Softmax regression: L·ªói t·∫£i model.")

else:
    # Th√¥ng b√°o ch·ªù
    st.info("‚¨ÜÔ∏è H√£y t·∫£i m·ªôt ·∫£nh l√™n ƒë·ªÉ c·∫£ hai m√¥ h√¨nh c√πng ph√¢n t√≠ch.")
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
