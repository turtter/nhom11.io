import streamlit as st
from PIL import Image, ImageDraw
import torch
import torchvision
import torchvision.transforms as T
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
<<<<<<< HEAD


# ================================
# 1ï¸âƒ£ HÃ m load model (sá»­a num_classes = 4)
# ================================
def load_model(weight_path):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1
    )

    # 3 lá»›p (non_defective_phone, defective, non-phone) + 1 background
    num_classes = 4

    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # Load trá»ng sá»‘ huáº¥n luyá»‡n
    state_dict = torch.load(weight_path, map_location="cpu")
    model.load_state_dict(state_dict)

=======
import os
import pickle
import numpy as np

# --- Import cÃ¡c thÆ° viá»‡n HOG ---
from skimage.transform import resize
from skimage.color import rgb2gray
from skimage.feature import hog

# ======================================================================
# MODEL 1: FASTER R-CNN (PhÃ¡t hiá»‡n Lá»—i)
# ======================================================================

# 1.1ï¸âƒ£ HÃ m load model (sá»­a num_classes = 4)
def load_model_fasterrcnn(weight_path):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1
    )
    num_classes = 4  # 3 lá»›p + 1 background
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    state_dict = torch.load(weight_path, map_location="cpu")
    model.load_state_dict(state_dict)
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
    model.eval()
    return model


<<<<<<< HEAD
# ================================
# 2ï¸âƒ£ Táº£i mÃ´ hÃ¬nh chá»‰ 1 láº§n
# ================================
@st.cache_resource
def get_model():
    model_path = "fasterrcnn_phone_defect1910.pth"  # Ä‘Æ°á»ng dáº«n file .pth cá»§a báº¡n
    model = load_model(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("âœ… Model loaded and cached.")
    return model, device


# ================================
# 3ï¸âƒ£ HÃ m dá»± Ä‘oÃ¡n cho Web App
# ================================
=======
# 1.2ï¸âƒ£ Táº£i mÃ´ hÃ¬nh chá»‰ 1 láº§n
@st.cache_resource
def get_model_fasterrcnn():
    model_path = "fasterrcnn_phone_defect1910.pth"  # Ä‘Æ°á»ng dáº«n file .pth cá»§a báº¡n
    model = load_model_fasterrcnn(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("âœ… Model 1 (Faster R-CNN) loaded and cached.")
    return model, device


# 1.3ï¸âƒ£ HÃ m dá»± Ä‘oÃ¡n cho Web App (Chá»‰ tráº£ vá» STATUS)
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
def predict_for_webapp(model, device, image_pil, score_thresh=0.6):
    transform = T.ToTensor()
    img_tensor = transform(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)[0]
<<<<<<< HEAD

    image_with_boxes = image_pil.copy()
    draw = ImageDraw.Draw(image_with_boxes)

    # Map ID -> NhÃ£n
    label_map = {
        1: "KHÃ”NG Lá»–I",
        2: "Bá»Š Lá»–I",
        3: "KHÃ”NG PHáº¢I ÄIá»†N THOáº I"
    }

=======
        
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
    has_detection = False
    found_defect = False
    found_nonphone = False

<<<<<<< HEAD
    for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            has_detection = True
            box = box.cpu().numpy()
            label_id = int(label.cpu().numpy())

            # MÃ u khung
            if label_id == 1:
                color = "lime"
            elif label_id == 2:
                color = "red"
                found_defect = True
            elif label_id == 3:
                color = "blue"
                found_nonphone = True
            else:
                color = "white"

            # Váº½ khung vÃ  nhÃ£n
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)
            text = f"{label_map.get(label_id, 'N/A')}: {score:.2f}"
            text_x, text_y = box[0], max(0, box[1] - 20)
            bbox = draw.textbbox((text_x, text_y), text)
            draw.rectangle(bbox, fill="black")
            draw.text((text_x, text_y), text, fill="yellow")

    # ================================
    # 4ï¸âƒ£ Logic káº¿t luáº­n
    # ================================
    if not has_detection or found_nonphone:
        return "NO_PHONE", image_with_boxes
    elif found_defect:
        return "DEFECTIVE", image_with_boxes
    else:
        return "NON_DEFECTIVE", image_with_boxes


# ================================
# 5ï¸âƒ£ Giao diá»‡n Streamlit
# ================================
st.set_page_config(layout="wide", page_title="Phone Defect Detection")

st.title("ðŸ“± á»¨ng dá»¥ng PhÃ¡t hiá»‡n Lá»—i Äiá»‡n thoáº¡i (3 lá»›p)")
st.write("Táº£i lÃªn áº£nh Ä‘iá»‡n thoáº¡i Ä‘á»ƒ mÃ´ hÃ¬nh phÃ¢n loáº¡i: **KHÃ”NG Lá»–I**, **Bá»Š Lá»–I**, hoáº·c **KHÃ”NG PHÃT HIá»†N RA ÄIá»†N THOáº I**.")

model, device = get_model()

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader("ðŸ“¤ Chá»n má»™t áº£nh", type=["jpg", "jpeg", "png"])

with col2:
    st.write("### ðŸ” Káº¿t quáº£ dá»± Ä‘oÃ¡n")

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        with st.spinner("Äang xá»­ lÃ½..."):
            detection_status, result_image = predict_for_webapp(model, device, image, score_thresh=0.6)

            if detection_status == "DEFECTIVE":
                st.error("âŒ **Káº¾T QUáº¢: PHÃT HIá»†N ÄIá»†N THOáº I Bá»Š Lá»–I (Vá»  hoáº·c Báº¨N )**")
            elif detection_status == "NON_DEFECTIVE":
                st.success("âœ… **Káº¾T QUáº¢: ÄIá»†N THOáº I KHÃ”NG Lá»–I**")
            elif detection_status == "NO_PHONE":
                st.warning("âš ï¸ **Káº¾T QUáº¢: KHÃ”NG PHÃT HIá»†N RA ÄIá»†N THOáº I**")

            st.image(result_image, caption="áº¢nh Káº¿t Quáº£", use_container_width=True)
    else:
        st.info("â¬†ï¸ HÃ£y táº£i má»™t áº£nh lÃªn Ä‘á»ƒ xem káº¿t quáº£.")
=======
    for score, label in zip(outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            has_detection = True
            label_id = int(label.cpu().numpy())
            if label_id == 2:
                found_defect = True
            elif label_id == 3:
                found_nonphone = True

    # 1.4ï¸âƒ£ Logic káº¿t luáº­n (KhÃ´ng tráº£ vá» áº£nh)
    if not has_detection or found_nonphone:
        return "NO_PHONE"
    elif found_defect:
        return "DEFECTIVE"
    else:
        return "NON_DEFECTIVE"


# ======================================================================
# MODEL 2: HOG + SOFTMAX (PhÃ¢n loáº¡i)
# ======================================================================

# 2.1ï¸âƒ£ --- CONFIG HOG (Pháº£i giá»‘ng há»‡t file train) ---
HOG_IMG_SIZE = (128, 64)
PIXELS_PER_CELL = (16, 16)
CELLS_PER_BLOCK = (2, 2)
ORIENTATIONS = 9
COLOR_BINS = 32
MODEL_PATH = os.path.join("outputs", "softmax_model_hog_hist.pkl")

# 2.2ï¸âƒ£ --- Táº£i Model Ä‘Ã£ huáº¥n luyá»‡n ---
@st.cache_resource
def load_model_hog():
    if not os.path.exists(MODEL_PATH):
        st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file model HOG táº¡i '{MODEL_PATH}'")
        return None  # Tráº£ vá» None náº¿u lá»—i
    print(f"Äang táº£i model HOG tá»« {MODEL_PATH}...")
    try:
        with open(MODEL_PATH, "rb") as f:
            model_data = pickle.load(f)
        print("Táº£i model HOG thÃ nh cÃ´ng.")
        return model_data
    except Exception as e:
        st.error(f"Lá»—i khi táº£i model HOG: {e}")
        return None # Tráº£ vá» None náº¿u lá»—i


# 2.3ï¸âƒ£ --- HÃ m tÃ­nh Softmax (Láº¥y tá»« file train) ---
def softmax_np(z):
    z = z - np.max(z, axis=1, keepdims=True)
    e = np.exp(z)
    return e / np.sum(e, axis=1, keepdims=True)


# 2.4ï¸âƒ£ --- HÃ m trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng HOG (ÄÃƒ Cáº¬P NHáº¬T) ---
def extract_hog_features(img_pil):
    try:
        img = np.array(img_pil)
        if img.ndim == 3 and img.shape[2] == 4:
            img = img[:, :, :3]  # Loáº¡i bá» kÃªnh Alpha
        resized_img = resize(img, HOG_IMG_SIZE, anti_aliasing=True)
        gray_img = rgb2gray(resized_img) if resized_img.ndim == 3 else resized_img
        features_hog = hog(gray_img, orientations=ORIENTATIONS,
                           pixels_per_cell=PIXELS_PER_CELL,
                           cells_per_block=CELLS_PER_BLOCK,
                           block_norm='L2-Hys',
                           visualize=False,
                           transform_sqrt=True)
        if resized_img.ndim == 3 and resized_img.shape[2] == 3:
            img_uint8 = (resized_img * 255).astype(np.uint8)
            hist_r = np.histogram(img_uint8[:, :, 0], bins=COLOR_BINS, range=(0, 256))[0]
            hist_g = np.histogram(img_uint8[:, :, 1], bins=COLOR_BINS, range=(0, 256))[0]
            hist_b = np.histogram(img_uint8[:, :, 2], bins=COLOR_BINS, range=(0, 256))[0]
            features_color_raw = np.concatenate((hist_r, hist_g, hist_b))
            features_color = features_color_raw / (features_color_raw.sum() + 1e-6)
        else:
            features_color = np.zeros(COLOR_BINS * 3)
        features = np.concatenate((features_hog, features_color))
        return features
    except Exception as e:
        print(f"Lá»—i khi trÃ­ch xuáº¥t HOG: {e}")
        return None


# ======================================================================
# 5ï¸âƒ£ Giao diá»‡n Streamlit ChÃ­nh (Káº¿t quáº£ lÃªn Ä‘áº§u)
# ======================================================================
st.set_page_config(layout="wide", page_title="Phone Analysis App")

st.title("ðŸ“± á»¨ng dá»¥ng PhÃ¢n tÃ­ch Äiá»‡n thoáº¡i")
st.write("Táº£i lÃªn má»™t áº£nh, cáº£ hai mÃ´ hÃ¬nh sáº½ cÃ¹ng phÃ¢n tÃ­ch vÃ  hiá»ƒn thá»‹ káº¿t quáº£ ngay bÃªn dÆ°á»›i.")

# --- Táº£i cáº£ hai model lÃªn trÆ°á»›c ---
model_rcnn, device_rcnn = get_model_fasterrcnn()
model_data_hog = load_model_hog()

# --- Táº¡o 1 file uploader duy nháº¥t ---
uploaded_file = st.file_uploader("ðŸ“¤ Chá»n má»™t áº£nh duy nháº¥t", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Má»Ÿ áº£nh Má»˜T Láº¦N
    image_pil = Image.open(uploaded_file).convert("RGB")

    # --- HIá»‚N THá»Š Káº¾T QUáº¢ (Theo yÃªu cáº§u) ---
    st.header("ðŸ” Káº¿t Quáº£ PhÃ¢n TÃ­ch")
    
    # Táº¡o 2 dÃ²ng trá»‘ng Ä‘á»ƒ chá»©a káº¿t quáº£
    # ChÃºng sáº½ Ä‘Æ°á»£c láº¥p Ä‘áº§y sau khi model cháº¡y xong
    result_placeholder_1 = st.empty()
    result_placeholder_2 = st.empty()

    # ThÃªm má»™t Ä‘Æ°á»ng káº»
    st.divider() 

    # --- HIá»‚N THá»Š áº¢NH Gá»C (BÃªn dÆ°á»›i káº¿t quáº£) ---
    st.header("ðŸ–¼ï¸ áº¢nh Gá»‘c ÄÃ£ Táº£i LÃªn")
    st.image(image_pil, caption="áº¢nh gá»‘c", use_container_width=True)
    
    # --- Xá»­ lÃ½ Model 1 (Faster R-CNN) ---
    with st.spinner("Model 1 (Faster R-CNN) Ä‘ang xá»­ lÃ½..."):
        detection_status = predict_for_webapp(model_rcnn, device_rcnn, image_pil.copy(), score_thresh=0.6)
        
        # Format káº¿t quáº£ Model 1 (ÄÃƒ Sá»¬A TÃŠN)
        result_text_1 = "### 1. Model Faster R-CNN: "
        if detection_status == "DEFECTIVE":
            result_text_1 += "âŒ **PHÃT HIá»†N Lá»–I (Vá» /Báº¨N)**"
        elif detection_status == "NON_DEFECTIVE":
            result_text_1 += "âœ… **KHÃ”NG Lá»–I**"
        elif detection_status == "NO_PHONE":
            result_text_1 += "âš ï¸ **KHÃ”NG PHÃT HIá»†N ÄT**"
        
        # Äáº©y káº¿t quáº£ vÃ o placeholder 1
        result_placeholder_1.markdown(result_text_1)

    # --- Xá»­ lÃ½ Model 2 (HOG + Softmax) ---
    with st.spinner("Model 2 (Softmax regression) Ä‘ang xá»­ lÃ½..."):
        if model_data_hog is not None:
            # Giáº£i nÃ©n cÃ¡c thÃ nh pháº§n model HOG
            W = model_data_hog["W"]
            b = model_data_hog["b"]
            mean = model_data_hog["mean"]
            std = model_data_hog["std"]
            label_map = model_data_hog["label_map"]
            inv_label_map = {v: k for k, v in label_map.items()}

            features = extract_hog_features(image_pil.copy())
            
            # Format káº¿t quáº£ Model 2 (ÄÃƒ Sá»¬A TÃŠN)
            result_text_2 = "### 2. Model Softmax regression: "
            if features is None:
                result_text_2 += "ðŸš« *KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh nÃ y.*"
            else:
                features_2d = features.reshape(1, -1)
                if features_2d.shape[1] != mean.shape[1]:
                    result_text_2 += f"ðŸš« *Lá»—i kÃ­ch thÆ°á»›c! (Cáº§n {mean.shape[1]}, nháº­n Ä‘Æ°á»£c {features_2d.shape[1]})*"
                else:
                    # Chuáº©n hÃ³a vÃ  dá»± Ä‘oÃ¡n
                    features_std = (features_2d - mean) / (std + 1e-12)
                    scores = features_std @ W + b
                    probs = softmax_np(scores)
                    pred_index = np.argmax(probs, axis=1)[0]
                    prediction_label = inv_label_map[pred_index]
                    probability = np.max(probs) * 100
                    
                    # Format káº¿t quáº£ Model 2
                    result_text_2 += f"**'{prediction_label}'** (Äá»™ tin cáº­y: {probability:.2f}%)"
            
            # Äáº©y káº¿t quáº£ vÃ o placeholder 2
            result_placeholder_2.markdown(result_text_2)
        else:
            result_placeholder_2.error("### 2. Model Softmax regression: Lá»—i táº£i model.")

else:
    # ThÃ´ng bÃ¡o chá»
    st.info("â¬†ï¸ HÃ£y táº£i má»™t áº£nh lÃªn Ä‘á»ƒ cáº£ hai mÃ´ hÃ¬nh cÃ¹ng phÃ¢n tÃ­ch.")
>>>>>>> cbf8d3664434d47193f6945a72824c8e80052ef5
