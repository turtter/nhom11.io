import streamlit as st
from PIL import Image, ImageDraw
import torch
import torchvision
import torchvision.transforms as T
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
import os
import pickle
import numpy as np

# --- Import c√°c th∆∞ vi·ªán HOG ---
from skimage.transform import resize
from skimage.color import rgb2gray
from skimage.feature import hog

# ======================================================================
# MODEL 1: FASTER R-CNN (Ph√°t hi·ªán L·ªói)
# ======================================================================

# 1.1Ô∏è‚É£ H√†m load model (s·ª≠a num_classes = 4)
def load_model_fasterrcnn(weight_path):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
        weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1
    )
    num_classes = 4  # 3 l·ªõp + 1 background
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    # Load tr·ªçng s·ªë hu·∫•n luy·ªán
    state_dict = torch.load(weight_path, map_location="cpu")
    model.load_state_dict(state_dict)
    model.eval()
    return model


# 1.2Ô∏è‚É£ T·∫£i m√¥ h√¨nh ch·ªâ 1 l·∫ßn
@st.cache_resource
def get_model_fasterrcnn():
    model_path = "fasterrcnn_phone_defect1910.pth"  # ƒë∆∞·ªùng d·∫´n file .pth c·ªßa b·∫°n
    model = load_model_fasterrcnn(model_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    print("‚úÖ Model 1 (Faster R-CNN) loaded and cached.")
    return model, device


# 1.3Ô∏è‚É£ H√†m d·ª± ƒëo√°n cho Web App
def predict_for_webapp(model, device, image_pil, score_thresh=0.6):
    transform = T.ToTensor()
    img_tensor = transform(image_pil).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(img_tensor)[0]

    image_with_boxes = image_pil.copy()
    draw = ImageDraw.Draw(image_with_boxes)

    # Map ID -> Nh√£n
    label_map = {
        1: "KH√îNG L·ªñI",
        2: "B·ªä L·ªñI",
        3: "KH√îNG PH·∫¢I ƒêI·ªÜN THO·∫†I"
    }

    has_detection = False
    found_defect = False
    found_nonphone = False

    for box, score, label in zip(outputs["boxes"], outputs["scores"], outputs["labels"]):
        if score > score_thresh:
            has_detection = True
            box = box.cpu().numpy()
            label_id = int(label.cpu().numpy())

            # M√†u khung
            if label_id == 1:
                color = "lime"
            elif label_id == 2:
                color = "red"
                found_defect = True
            elif label_id == 3:
                color = "blue"
                found_nonphone = True
            else:
                color = "white"

            # V·∫Ω khung v√† nh√£n
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline=color, width=3)
            text = f"{label_map.get(label_id, 'N/A')}: {score:.2f}"
            text_x, text_y = box[0], max(0, box[1] - 20)
            bbox = draw.textbbox((text_x, text_y), text)
            draw.rectangle(bbox, fill="black")
            draw.text((text_x, text_y), text, fill="yellow")

    # 1.4Ô∏è‚É£ Logic k·∫øt lu·∫≠n
    if not has_detection or found_nonphone:
        return "NO_PHONE", image_with_boxes
    elif found_defect:
        return "DEFECTIVE", image_with_boxes
    else:
        return "NON_DEFECTIVE", image_with_boxes


# ======================================================================
# MODEL 2: HOG + SOFTMAX (Ph√¢n lo·∫°i)
# ======================================================================

# 2.1Ô∏è‚É£ --- CONFIG HOG (Ph·∫£i gi·ªëng h·ªát file train) ---
HOG_IMG_SIZE = (128, 64)
PIXELS_PER_CELL = (16, 16)
CELLS_PER_BLOCK = (2, 2)
ORIENTATIONS = 9
COLOR_BINS = 32
MODEL_PATH = os.path.join("outputs", "softmax_model_hog_hist.pkl")

# 2.2Ô∏è‚É£ --- T·∫£i Model ƒë√£ hu·∫•n luy·ªán ---
@st.cache_resource
def load_model_hog():
    if not os.path.exists(MODEL_PATH):
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file model HOG t·∫°i '{MODEL_PATH}'")
        st.error("Vui l√≤ng ƒë·∫£m b·∫£o file model ƒë√£ ƒë∆∞·ª£c ƒë·∫©y l√™n GitHub v√† n·∫±m trong th∆∞ m·ª•c 'outputs'.")
        st.stop()  # D·ª´ng ·ª©ng d·ª•ng

    print(f"ƒêang t·∫£i model HOG t·ª´ {MODEL_PATH}...")
    try:
        with open(MODEL_PATH, "rb") as f:
            model_data = pickle.load(f)
        print("T·∫£i model HOG th√†nh c√¥ng.")
        return model_data
    except FileNotFoundError:
        st.error(f"L·ªói FileNotFoundError: Kh√¥ng t√¨m th·∫•y file model HOG t·∫°i '{MODEL_PATH}'.")
        st.error("H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n v√† ƒë·∫£m b·∫£o file ƒë√£ ƒë∆∞·ª£c commit l√™n GitHub.")
        st.stop()
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i model HOG: {e}")
        st.stop()


# 2.3Ô∏è‚É£ --- H√†m t√≠nh Softmax (L·∫•y t·ª´ file train) ---
def softmax_np(z):
    z = z - np.max(z, axis=1, keepdims=True)
    e = np.exp(z)
    return e / np.sum(e, axis=1, keepdims=True)


# 2.4Ô∏è‚É£ --- H√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG (ƒê√É C·∫¨P NH·∫¨T) ---
def extract_hog_features(img_pil):
    try:
        img = np.array(img_pil)
        if img.ndim == 3 and img.shape[2] == 4:
            img = img[:, :, :3]  # Lo·∫°i b·ªè k√™nh Alpha

        resized_img = resize(img, HOG_IMG_SIZE, anti_aliasing=True)
        gray_img = rgb2gray(resized_img) if resized_img.ndim == 3 else resized_img

        # --- 1. Tr√≠ch xu·∫•t HOG (t·ª´ ·∫£nh x√°m) ---
        features_hog = hog(gray_img, orientations=ORIENTATIONS,
                           pixels_per_cell=PIXELS_PER_CELL,
                           cells_per_block=CELLS_PER_BLOCK,
                           block_norm='L2-Hys',
                           visualize=False,
                           transform_sqrt=True)

        # --- 2. Tr√≠ch xu·∫•t Color Histogram (t·ª´ ·∫£nh m√†u) ---
        if resized_img.ndim == 3 and resized_img.shape[2] == 3:
            img_uint8 = (resized_img * 255).astype(np.uint8)
            hist_r = np.histogram(img_uint8[:, :, 0], bins=COLOR_BINS, range=(0, 256))[0]
            hist_g = np.histogram(img_uint8[:, :, 1], bins=COLOR_BINS, range=(0, 256))[0]
            hist_b = np.histogram(img_uint8[:, :, 2], bins=COLOR_BINS, range=(0, 256))[0]
            features_color_raw = np.concatenate((hist_r, hist_g, hist_b))
            features_color = features_color_raw / (features_color_raw.sum() + 1e-6)
        else:
            features_color = np.zeros(COLOR_BINS * 3)

        # --- 3. N·ªëi 2 ƒë·∫∑c tr∆∞ng ---
        features = np.concatenate((features_hog, features_color))
        return features

    except Exception as e:
        print(f"L·ªói khi tr√≠ch xu·∫•t HOG: {e}")
        return None


# ======================================================================
# 5Ô∏è‚É£ Giao di·ªán Streamlit Ch√≠nh (S·ª≠ d·ª•ng Tabs)
# ======================================================================
st.set_page_config(layout="wide", page_title="Phone Analysis App")

st.title("üì± ·ª®ng d·ª•ng Ph√¢n t√≠ch ƒêi·ªán tho·∫°i")
st.write("S·ª≠ d·ª•ng tab b√™n d∆∞·ªõi ƒë·ªÉ ch·ªçn m√¥ h√¨nh b·∫°n mu·ªën d√πng.")

tab1, tab2 = st.tabs([
    "M√¥ h√¨nh 1: Ph√°t hi·ªán L·ªói (Faster R-CNN)",
    "M√¥ h√¨nh 2: Ph√¢n lo·∫°i (HOG + Histogram)"
])

# --- Giao di·ªán cho Tab 1: Faster R-CNN ---
with tab1:
    st.header("1Ô∏è‚É£ Ph√°t hi·ªán L·ªói ƒêi·ªán tho·∫°i (3 l·ªõp)")
    st.write("T·∫£i l√™n ·∫£nh ƒëi·ªán tho·∫°i ƒë·ªÉ m√¥ h√¨nh ph√¢n lo·∫°i: **KH√îNG L·ªñI**, **B·ªä L·ªñI**, ho·∫∑c **KH√îNG PH√ÅT HI·ªÜN RA ƒêI·ªÜN THO·∫†I**.")

    # T·∫£i model 1
    model_rcnn, device_rcnn = get_model_fasterrcnn()

    col1, col2 = st.columns(2)

    with col1:
        # Th√™m key="uploader1" ƒë·ªÉ ph√¢n bi·ªát v·ªõi uploader ·ªü tab 2
        uploaded_file_1 = st.file_uploader("üì§ Ch·ªçn m·ªôt ·∫£nh (Model 1)", type=["jpg", "jpeg", "png"], key="uploader1")

    with col2:
        st.write("### üîç K·∫øt qu·∫£ d·ª± ƒëo√°n (Model 1)")

        if uploaded_file_1 is not None:
            image_1 = Image.open(uploaded_file_1).convert("RGB")
            with st.spinner("ƒêang x·ª≠ l√Ω (Model 1)..."):
                detection_status, result_image = predict_for_webapp(model_rcnn, device_rcnn, image_1, score_thresh=0.6)

                if detection_status == "DEFECTIVE":
                    st.error("‚ùå **K·∫æT QU·∫¢: PH√ÅT HI·ªÜN ƒêI·ªÜN THO·∫†I B·ªä L·ªñI (V·ª† ho·∫∑c B·∫®N )**")
                elif detection_status == "NON_DEFECTIVE":
                    st.success("‚úÖ **K·∫æT QU·∫¢: ƒêI·ªÜN THO·∫†I KH√îNG L·ªñI**")
                elif detection_status == "NO_PHONE":
                    st.warning("‚ö†Ô∏è **K·∫æT QU·∫¢: KH√îNG PH√ÅT HI·ªÜN RA ƒêI·ªÜN THO·∫†I**")

                st.image(result_image, caption="·∫¢nh K·∫øt Qu·∫£ (Model 1)", use_container_width=True)
        else:
            st.info("‚¨ÜÔ∏è H√£y t·∫£i m·ªôt ·∫£nh l√™n cho Model 1 ƒë·ªÉ xem k·∫øt qu·∫£.")


# --- Giao di·ªán cho Tab 2: HOG + Softmax ---
with tab2:
    st.header("2Ô∏è‚É£ Ph√¢n lo·∫°i ·∫£nh ƒëi·ªán tho·∫°i (HOG + Histogram)")
    
    # T·∫£i model 2
    model_data_hog = load_model_hog()

    # L·∫•y c√°c th√†nh ph·∫ßn t·ª´ model
    W = model_data_hog["W"]
    b = model_data_hog["b"]
    mean = model_data_hog["mean"]
    std = model_data_hog["std"]
    label_map = model_data_hog["label_map"]
    inv_label_map = {v: k for k, v in label_map.items()}

    # 1. T·∫°o n√∫t t·∫£i file (Th√™m key="uploader2")
    uploaded_file_2 = st.file_uploader("Ch·ªçn m·ªôt ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n (Model 2):",
                                     type=["jpg", "jpeg", "png", "bmp"],
                                     key="uploader2")

    if uploaded_file_2 is not None:
        # 2. Hi·ªÉn th·ªã ·∫£nh
        img_pil_2 = Image.open(uploaded_file_2)
        st.image(img_pil_2, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)

        # 3. T·∫°o n√∫t d·ª± ƒëo√°n
        if st.button("D·ª± ƒëo√°n (Model 2)", key="button2"):
            # 4. X·ª≠ l√Ω v√† d·ª± ƒëo√°n
            with st.spinner("ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng v√† d·ª± ƒëo√°n (Model 2)..."):
                features = extract_hog_features(img_pil_2)

                if features is None:
                    st.error("Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh n√†y.")
                else:
                    # Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
                    features_2d = features.reshape(1, -1)  # -> (1, 852)

                    # Ki·ªÉm tra k√≠ch th∆∞·ªõc tr∆∞·ªõc khi chu·∫©n h√≥a
                    if features_2d.shape[1] != mean.shape[1]:
                        st.error(
                            f"L·ªói k√≠ch th∆∞·ªõc ƒë·∫∑c tr∆∞ng! Model mong ƒë·ª£i {mean.shape[1]}, nh∆∞ng nh·∫≠n ƒë∆∞·ª£c {features_2d.shape[1]}.")
                    else:
                        features_std = (features_2d - mean) / (std + 1e-12)

                        # D·ª± ƒëo√°n
                        scores = features_std @ W + b
                        probs = softmax_np(scores)

                        pred_index = np.argmax(probs, axis=1)[0]
                        prediction_label = inv_label_map[pred_index]
                        probability = np.max(probs) * 100

                        # 5. Hi·ªÉn th·ªã k·∫øt qu·∫£
                        st.success(f"**K·∫øt qu·∫£ (Model 2):** '{prediction_label}'")
                        st.info(f"**ƒê·ªô tin c·∫≠y:** {probability:.2f}%")
